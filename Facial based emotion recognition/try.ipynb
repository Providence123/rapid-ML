{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\x-cla\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "from constants import *\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from emotion_recognition import EmotionRecognition\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cascade_classifier = cv2.CascadeClassifier(CASC_PATH)\n",
    "\n",
    "#format jpg/png file to fit into network size\n",
    "def format_image(image):\n",
    "    image = np.asarray(image)\n",
    "    if len(image.shape) > 2 and image.shape[2] == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_GRAYSCALE)\n",
    "    faces = cascade_classifier.detectMultiScale(\n",
    "        image,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5\n",
    "    )\n",
    "    # None is we don't found an image\n",
    "    if not len(faces) > 0:\n",
    "        return None\n",
    "    max_area_face = faces[0]\n",
    "    for face in faces:\n",
    "        if face[2] * face[3] > max_area_face[2] * max_area_face[3]:\n",
    "            max_area_face = face\n",
    "    # Chop image to face\n",
    "    face = max_area_face\n",
    "    image = image[face[1]:(face[1] + face[2]), face[0]:(face[0] + face[3])]\n",
    "    # Resize image to network size\n",
    "    try:\n",
    "        image = cv2.resize(image, (SIZE_FACE, SIZE_FACE),\n",
    "                           interpolation=cv2.INTER_CUBIC) / 255.\n",
    "    except Exception:\n",
    "        print(\"[+] Problem during resize\")\n",
    "        return None\n",
    "\n",
    "    return image\n",
    "\n",
    "#format jpg/png file (without normalization)\n",
    "def form(image):\n",
    "    image = np.asarray(image)\n",
    "    if len(image.shape) > 2 and image.shape[2] == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_GRAYSCALE)\n",
    "    faces = cascade_classifier.detectMultiScale(\n",
    "        image,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5\n",
    "    )\n",
    "    # None is we don't found an image\n",
    "    if not len(faces) > 0:\n",
    "        return None\n",
    "    max_area_face = faces[0]\n",
    "    for face in faces:\n",
    "        if face[2] * face[3] > max_area_face[2] * max_area_face[3]:\n",
    "            max_area_face = face\n",
    "    # Chop image to face\n",
    "    face = max_area_face\n",
    "    image = image[face[1]:(face[1] + face[2]), face[0]:(face[0] + face[3])]\n",
    "    # Resize image to network size\n",
    "    try:\n",
    "        image = cv2.resize(image, (SIZE_FACE, SIZE_FACE),\n",
    "                           interpolation=cv2.INTER_CUBIC)\n",
    "    except Exception:\n",
    "        print(\"[+] Problem during resize\")\n",
    "        return None\n",
    "\n",
    "    return image\n",
    "\n",
    "#im = Image.open(\"0.jpg\")\n",
    "#hi = form(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def infer(image):\n",
    "    \n",
    "    #Load model\n",
    "    network = EmotionRecognition()\n",
    "    network.build_network()\n",
    "    \n",
    "    #Predict\n",
    "    result = network.predict(format_image(image))\n",
    "    label = np.argmax(result[0])\n",
    "    print(\"Emotion: \" + str(EMOTIONS[np.argmax(result[0])]))\n",
    "    return label\n",
    "\n",
    "#im = Image.open(\"0.jpg\")\n",
    "#infer(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Building CNN\n",
      "WARNING:tensorflow:From C:\\Users\\x-cla\\Anaconda3\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From C:\\Users\\x-cla\\Anaconda3\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Emotion: fearful\n"
     ]
    }
   ],
   "source": [
    "def collect(image):\n",
    "    #Get predicted label\n",
    "    labell = infer(image)\n",
    "    \n",
    "    #Change image to string of values\n",
    "    data = form(image)\n",
    "    l=data.tolist()\n",
    "    new = []\n",
    "    for sublist in l:\n",
    "        for item in sublist:\n",
    "            new.append(item)\n",
    "    stri=' '.join([str(int(i)) for i in new])\n",
    "    \n",
    "    #Add to csv file\n",
    "    row=[str(labell), stri,'Training' ]\n",
    "    with open(\"./collected/collect.csv\", 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "\n",
    "#im = Image.open(\"0.jpg\")\n",
    "#collect(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reframe():\n",
    "    \n",
    "    #Get data from collect.csv and add it to dataset\n",
    "    with open(\"./collected/collect.csv\", newline = '') as f_out, open(\"./data/test.csv\", 'a', newline='') as f_in:\n",
    "        reader = csv.reader(f_out)\n",
    "        next(reader) #skip first row\n",
    "        writer = csv.writer(f_in)\n",
    "        for row in reader:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    os.system(\"python3 emotion_recognition.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
